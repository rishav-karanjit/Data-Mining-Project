{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73135157-35fc-4f81-9970-ee1dd2629234",
   "metadata": {},
   "source": [
    "# Data Mining (CpSc 8650) Course Project  Quality Evaluation of Skull Stripped Brain MRI Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "faa61c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import nibabel as nib\n",
    "import random\n",
    "import csv\n",
    "from scipy import ndimage\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras.optimizers as optimizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras import layers\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f38ebf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and return data \n",
    "def load_data(csv_file_path, test_size = 0.3, x_names = [], y_names = []):\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    Load training data and split it into training and validation set\n",
    "    \"\"\"\n",
    "    print (\"Loading data from: \",csv_file_path)\n",
    "    #reads CSV file into a single dataframe variable\n",
    "    data_df = pd.read_csv(csv_file_path, names=x_names+y_names, skiprows=1)\n",
    "\n",
    "    #yay dataframes, we can select rows and columns by their names\n",
    "    X = data_df[x_names].values\n",
    "    #and our steering commands as our output data\n",
    "    y = data_df[y_names ].values\n",
    "\n",
    "    return X, y\n",
    "\n",
    "def read_nifti_file(filepath):\n",
    "    \"\"\"Read and load volume\"\"\"\n",
    "    # Read file\n",
    "    scan = nib.load(filepath)\n",
    "    # Get raw data\n",
    "    scan = scan.get_fdata()\n",
    "    return scan\n",
    "\n",
    "\n",
    "def normalize(volume):\n",
    "    \"\"\"Normalize the volume\"\"\"\n",
    "    min = -1000\n",
    "    max = 400\n",
    "    volume[volume < min] = min\n",
    "    volume[volume > max] = max\n",
    "    volume = (volume - min) / (max - min)\n",
    "    volume = volume.astype(\"float32\")\n",
    "    return volume\n",
    "\n",
    "\n",
    "def resize_volume(img):\n",
    "    \"\"\"Resize across z-axis\"\"\"\n",
    "    # Set the desired depth\n",
    "    desired_depth = 64\n",
    "    desired_width = 128\n",
    "    desired_height = 128\n",
    "    # Get current depth\n",
    "    current_depth = img.shape[-1]\n",
    "    current_width = img.shape[0]\n",
    "    current_height = img.shape[1]\n",
    "    # Compute depth factor\n",
    "    depth = current_depth / desired_depth\n",
    "    width = current_width / desired_width\n",
    "    height = current_height / desired_height\n",
    "    depth_factor = 1 / depth\n",
    "    width_factor = 1 / width\n",
    "    height_factor = 1 / height\n",
    "    # Rotate\n",
    "    img = ndimage.rotate(img, 90, reshape=False)\n",
    "    # Resize across z-axis\n",
    "    img = ndimage.zoom(img, (width_factor, height_factor, depth_factor), order=1)\n",
    "    return img\n",
    "\n",
    "def process_scan(path):\n",
    "    \n",
    "    \"\"\"Read and resize volume\"\"\"\n",
    "    # Read scan\n",
    "    volume = read_nifti_file(path)\n",
    "    # Normalize\n",
    "    volume = normalize(volume)\n",
    "    #Resize width, height and depth\n",
    "    volume = resize_volume(volume)\n",
    "    \n",
    "    return volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68a0d543-e1dc-4e17-bcaa-84de77a0b007",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def rotate(volume):\n",
    "    \"\"\"Rotate the volume by a few degrees\"\"\"\n",
    "\n",
    "    def scipy_rotate(volume):\n",
    "        # define some rotation angles\n",
    "        angles = [0,-5,5,-10,10,15,-15]\n",
    "        # pick angles at random\n",
    "        angle = random.choice(angles)\n",
    "        # rotate volume\n",
    "        volume = ndimage.rotate(volume, angle, reshape=False)\n",
    "        volume[volume < 0] = 0\n",
    "        volume[volume > 1] = 1\n",
    "        return volume\n",
    "\n",
    "    augmented_volume = tf.numpy_function(scipy_rotate, [volume], tf.float32)\n",
    "    return augmented_volume\n",
    "\n",
    "\n",
    "def train_preprocessing(volume, labels):\n",
    "    \"\"\"Process training data by rotating and adding a channel.\"\"\"\n",
    "    # Rotate volume\n",
    "    volume = rotate(volume)\n",
    "    volume = tf.expand_dims(volume, axis=3)\n",
    "    return volume, labels\n",
    "\n",
    "\n",
    "def validation_preprocessing(volume, label):\n",
    "    \"\"\"Process validation data by only adding a channel.\"\"\"\n",
    "    volume = tf.expand_dims(volume, axis=3)\n",
    "    return volume, label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3db25cb-dbba-4d77-b1dc-23effcff6aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from:  D:\\OneDrive - Clemson University\\Clemson Courses\\Data mining\\Project\\Project\\dataset\\Label_file.csv\n"
     ]
    }
   ],
   "source": [
    "label_file_path = os.path.join(os.path.abspath(os.pardir), \"dataset\", \"Label_file.csv\")\n",
    "X, y = load_data(label_file_path, x_names = [\"Filename\"], y_names = [\"Recognizable-Facial-Feature\",\"Brain-Feature-Loss\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87400c32-63de-40c7-ba51-473811334b03",
   "metadata": {},
   "source": [
    "## Displaying Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73c738b4-33b4-4ee0-83ef-a4db05a4b52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "model = keras.models.load_model('3d_image_classification_relu.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7da1916b-d550-492e-a473-333f2dd46c88",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold:1\n",
      "Data Loaded\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.99      0.99      0.99       506\n",
      "        True       0.99      0.99      0.99       542\n",
      "\n",
      "    accuracy                           0.99      1048\n",
      "   macro avg       0.99      0.99      0.99      1048\n",
      "weighted avg       0.99      0.99      0.99      1048\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      0.97      0.99       555\n",
      "        True       0.97      1.00      0.98       493\n",
      "\n",
      "    accuracy                           0.99      1048\n",
      "   macro avg       0.99      0.99      0.99      1048\n",
      "weighted avg       0.99      0.99      0.99      1048\n",
      "\n",
      "Fold:2\n",
      "Data Loaded\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.99      0.99      0.99       480\n",
      "        True       0.99      0.99      0.99       569\n",
      "\n",
      "    accuracy                           0.99      1049\n",
      "   macro avg       0.99      0.99      0.99      1049\n",
      "weighted avg       0.99      0.99      0.99      1049\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      0.98      0.99       581\n",
      "        True       0.97      1.00      0.99       468\n",
      "\n",
      "    accuracy                           0.99      1049\n",
      "   macro avg       0.99      0.99      0.99      1049\n",
      "weighted avg       0.99      0.99      0.99      1049\n",
      "\n",
      "Fold:3\n",
      "Data Loaded\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.99      0.99      0.99       509\n",
      "        True       0.99      0.99      0.99       540\n",
      "\n",
      "    accuracy                           0.99      1049\n",
      "   macro avg       0.99      0.99      0.99      1049\n",
      "weighted avg       0.99      0.99      0.99      1049\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      0.98      0.99       551\n",
      "        True       0.98      1.00      0.99       498\n",
      "\n",
      "    accuracy                           0.99      1049\n",
      "   macro avg       0.99      0.99      0.99      1049\n",
      "weighted avg       0.99      0.99      0.99      1049\n",
      "\n",
      "Fold:4\n",
      "Data Loaded\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.99      0.99      0.99       491\n",
      "        True       0.99      0.99      0.99       558\n",
      "\n",
      "    accuracy                           0.99      1049\n",
      "   macro avg       0.99      0.99      0.99      1049\n",
      "weighted avg       0.99      0.99      0.99      1049\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      0.98      0.99       570\n",
      "        True       0.97      1.00      0.98       479\n",
      "\n",
      "    accuracy                           0.99      1049\n",
      "   macro avg       0.98      0.99      0.99      1049\n",
      "weighted avg       0.99      0.99      0.99      1049\n",
      "\n",
      "Fold:5\n",
      "Data Loaded\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.99      0.99      0.99       490\n",
      "        True       0.99      0.99      0.99       559\n",
      "\n",
      "    accuracy                           0.99      1049\n",
      "   macro avg       0.99      0.99      0.99      1049\n",
      "weighted avg       0.99      0.99      0.99      1049\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      0.98      0.99       571\n",
      "        True       0.97      1.00      0.98       478\n",
      "\n",
      "    accuracy                           0.99      1049\n",
      "   macro avg       0.98      0.99      0.99      1049\n",
      "weighted avg       0.99      0.99      0.99      1049\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "skf = KFold(n_splits=5,shuffle=True,random_state=1)\n",
    "skf.get_n_splits(X, y)\n",
    "fold = 0\n",
    "\n",
    "for train_index, test_index in skf.split(X):\n",
    "    fold+=1\n",
    "    print(\"Fold:\"+str(fold))\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    iteration=0\n",
    "\n",
    "    outfileTrain = \"Fold \" + str(fold) + \" Checkpoints.pkl\"\n",
    "    outfileTest = \"Fold \" + str(fold) + \" Checkpoints test set.pkl\"\n",
    "\n",
    "    with open(outfileTrain, \"rb\") as f:\n",
    "        [X_train_data, abc] = pickle.load(f)\n",
    "    with open(outfileTest, \"rb\") as f:\n",
    "        [X_valid_data] = pickle.load(f)\n",
    "    print(\"Data Loaded\")\n",
    "    \n",
    "    X_pred = model.predict(tf.expand_dims(X_train_data, axis=4))\n",
    "    Face_pred = []\n",
    "    Brain_pred = []\n",
    "    Face_true = []\n",
    "    Brain_true = []\n",
    "    \n",
    "    len(Face_pred)\n",
    "    dataset_i = 0\n",
    "    for single_prediction in X_pred:\n",
    "        Face_pred.append(single_prediction[0]>0.5)\n",
    "        Brain_pred.append(single_prediction[1]>0.5)\n",
    "        \n",
    "        Face_true.append(y_train[dataset_i][0])\n",
    "        Brain_true.append(y_train[dataset_i][1])\n",
    "        dataset_i+=1\n",
    "    \n",
    "    print(classification_report(Face_true, Face_pred))\n",
    "    print(classification_report(Brain_true, Brain_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b5fd49-c2f8-4f38-a1ca-c44f7a94576d",
   "metadata": {},
   "source": [
    "### Predict with a image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96dcc47d-e55a-4064-bb54-2b08611541d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "model = keras.models.load_model(\"3d_image_classification_relu.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c009be50",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = process_scan('../dataset/files/IXI002-Guys-0828-T1_bse_less_s5_r1.nii.gz')\n",
    "file = tf.expand_dims(file, axis=0)\n",
    "\n",
    "prediction = model.predict(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a948819-2207-40ef-b4fb-7196b1fbec4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face Recognizable: True\n",
      "Brain Feature loss: False\n"
     ]
    }
   ],
   "source": [
    "print(\"Face Recognizable:\",prediction[0][0]>0.5)\n",
    "print(\"Brain Feature loss:\",prediction[0][1]>0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b9e2c55-c95a-4bee-83d7-87402b0907ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of Face Recognizable 0.99927604\n",
      "Probability of Brain Feature loss: 0.00049352646\n"
     ]
    }
   ],
   "source": [
    "print(\"Probability of Face Recognizable\",prediction[0][0])\n",
    "print(\"Probability of Brain Feature loss:\",prediction[0][1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
